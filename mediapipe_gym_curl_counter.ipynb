{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "daeca037",
   "metadata": {},
   "source": [
    "# Contents of this project\n",
    "\n",
    "1.   Setting up the media Pipe\n",
    "2.   Estimationg poses\n",
    "3.   Extractiong joint coordinates\n",
    "4.   Calaculating angles between joints\n",
    "5.   Building a gym curl counter \n",
    "\n",
    "you can find repetitive code in each cell as i am trying to buld the code step by step so that everyone can undersand each ane ever step\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ed2c767",
   "metadata": {},
   "source": [
    "# Install and import dependecies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "048027df",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting mediapipe\n",
      "  Downloading mediapipe-0.8.9.1-cp38-cp38-win_amd64.whl (48.5 MB)\n",
      "Collecting opencv-contrib-python\n",
      "  Downloading opencv_contrib_python-4.5.5.62-cp36-abi3-win_amd64.whl (42.2 MB)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\muddu krishna\\anaconda3\\lib\\site-packages (from mediapipe) (3.3.4)\n",
      "Requirement already satisfied: attrs>=19.1.0 in c:\\users\\muddu krishna\\anaconda3\\lib\\site-packages (from mediapipe) (20.3.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\muddu krishna\\anaconda3\\lib\\site-packages (from mediapipe) (1.20.1)\n",
      "Collecting protobuf>=3.11.4\n",
      "  Downloading protobuf-3.19.4-cp38-cp38-win_amd64.whl (895 kB)\n",
      "Collecting absl-py\n",
      "  Downloading absl_py-1.0.0-py3-none-any.whl (126 kB)\n",
      "Requirement already satisfied: six in c:\\users\\muddu krishna\\anaconda3\\lib\\site-packages (from absl-py->mediapipe) (1.15.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\muddu krishna\\anaconda3\\lib\\site-packages (from matplotlib->mediapipe) (0.10.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in c:\\users\\muddu krishna\\anaconda3\\lib\\site-packages (from matplotlib->mediapipe) (2.4.7)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\muddu krishna\\anaconda3\\lib\\site-packages (from matplotlib->mediapipe) (8.2.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\muddu krishna\\anaconda3\\lib\\site-packages (from matplotlib->mediapipe) (1.3.1)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in c:\\users\\muddu krishna\\anaconda3\\lib\\site-packages (from matplotlib->mediapipe) (2.8.1)\n",
      "Installing collected packages: protobuf, opencv-contrib-python, absl-py, mediapipe\n",
      "Successfully installed absl-py-1.0.0 mediapipe-0.8.9.1 opencv-contrib-python-4.5.5.62 protobuf-3.19.4\n",
      "Collecting opencv-python\n",
      "  Downloading opencv_python-4.5.5.62-cp36-abi3-win_amd64.whl (35.4 MB)\n",
      "Requirement already satisfied: numpy>=1.17.3 in c:\\users\\muddu krishna\\anaconda3\\lib\\site-packages (from opencv-python) (1.20.1)\n",
      "Installing collected packages: opencv-python\n",
      "Successfully installed opencv-python-4.5.5.62\n"
     ]
    }
   ],
   "source": [
    "!pip install mediapipe\n",
    "!pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "697fb634",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_pose = mp.solutions.pose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "ff36aea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# VIDEO FEED\n",
    "# for doing any real time estimation this block of code is more use full\n",
    "\n",
    "\n",
    "cap=cv.VideoCapture(0) #using this we can use our video input decice to input the video\n",
    "cap.set(cv.CAP_PROP_FRAME_WIDTH, 300)\n",
    "cap.set(cv.CAP_PROP_FRAME_HEIGHT, 400)\n",
    "width = cap.get(cv.CAP_PROP_FRAME_WIDTH)\n",
    "height = cap.get(cv.CAP_PROP_FRAME_HEIGHT)\n",
    "while cap.isOpened(): # this is going to loop through the live feed \n",
    "    ret , frame = cap.read()\n",
    "    cv.imshow('Mediapipe Feed',frame) #this  will give us a pope up on the screen and help us to visuva;ize the feed\n",
    "    frame.shape\n",
    "    if cv.waitKey(10) & 0xFF == ord('q'): # this is used to close our screen it checks weather the user is hitting q to close the wondow\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09d8e825",
   "metadata": {},
   "source": [
    "# Make detections "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f9f8da00",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cap=cv.VideoCapture(0) #using this we can use our video input decice to input the video\n",
    "## setting up mediia pipe instance\n",
    "with mp_pose.Pose(min_detection_confidence=0.5 , min_tracking_confidence = 0.5) as pose: # our detection confidance will be 50% and tracking confdence is 50% the line is accessible with variable pose \n",
    "    while cap.isOpened(): # this is going to loop through the live feed \n",
    "        ret , frame = cap.read()\n",
    "        \n",
    "        # RECOLOR IMAGE TO RGB\n",
    "        image= cv.cvtColor(frame,cv.COLOR_BGR2RGB) ## media pile wants the image in a specific format so we are re arranging the image here\n",
    "        image.flags.writeable = False\n",
    "        \n",
    "        # MAKE DETECTIONS\n",
    "        results= pose.process(image) ## using pose variable we are processing the image and making detections in the image and storing them in results variable \n",
    "        \n",
    "        # RECOLOURING BACK TO BGR\n",
    "        image.flags.writeable = True\n",
    "        image = cv.cvtColor(image,cv.COLOR_RGB2BGR) # now we are rearranging back in to the format which open cv accepts \n",
    "        \n",
    "        \n",
    "        #RENDERING DETECTIONS\n",
    "        mp_drawing.draw_landmarks(image,results.pose_landmarks,mp_pose.POSE_CONNECTIONS,\n",
    "                                  mp_drawing.DrawingSpec(color = (245,117,66), thickness = 2 , circle_radius = 2), ## this is the land mard drawing spec\n",
    "                                  mp_drawing.DrawingSpec(color = (245,66,280), thickness = 2 , circle_radius = 2)  ## this is the connection drawing spec \n",
    "                                 #DrawingSpec is the specification of a drawing component\n",
    "                                 )\n",
    "        \n",
    "        cv.imshow('Mediapipe Feed',image) #this  will give us a pope up on the screen and help us to visuva;ize the feed\n",
    "\n",
    "        if cv.waitKey(10) & 0xFF == ord('q'): # this is used to close our screen it checks weather the user is hitting q to close the wondow\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "358bd5a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "landmark {\n",
       "  x: 0.8756123781204224\n",
       "  y: 0.5033583641052246\n",
       "  z: -0.2637902796268463\n",
       "  visibility: 0.9953256249427795\n",
       "}\n",
       "landmark {\n",
       "  x: 0.8785083889961243\n",
       "  y: 0.4526787996292114\n",
       "  z: -0.1972939819097519\n",
       "  visibility: 0.9925546050071716\n",
       "}\n",
       "landmark {\n",
       "  x: 0.8805826902389526\n",
       "  y: 0.4527279734611511\n",
       "  z: -0.19771984219551086\n",
       "  visibility: 0.992730975151062\n",
       "}\n",
       "landmark {\n",
       "  x: 0.8826096653938293\n",
       "  y: 0.45274844765663147\n",
       "  z: -0.19764716923236847\n",
       "  visibility: 0.9921512007713318\n",
       "}\n",
       "landmark {\n",
       "  x: 0.8573952913284302\n",
       "  y: 0.44346803426742554\n",
       "  z: -0.32677537202835083\n",
       "  visibility: 0.9952601194381714\n",
       "}\n",
       "landmark {\n",
       "  x: 0.843019962310791\n",
       "  y: 0.4359240233898163\n",
       "  z: -0.3269352912902832\n",
       "  visibility: 0.9963721632957458\n",
       "}\n",
       "landmark {\n",
       "  x: 0.8245887756347656\n",
       "  y: 0.4266514480113983\n",
       "  z: -0.3275737166404724\n",
       "  visibility: 0.9964526891708374\n",
       "}\n",
       "landmark {\n",
       "  x: 0.8420118093490601\n",
       "  y: 0.45103058218955994\n",
       "  z: 0.14528468251228333\n",
       "  visibility: 0.9910065531730652\n",
       "}\n",
       "landmark {\n",
       "  x: 0.7575161457061768\n",
       "  y: 0.42574137449264526\n",
       "  z: -0.4331439435482025\n",
       "  visibility: 0.9976625442504883\n",
       "}\n",
       "landmark {\n",
       "  x: 0.8602110743522644\n",
       "  y: 0.5599480867385864\n",
       "  z: -0.12534335255622864\n",
       "  visibility: 0.9945494532585144\n",
       "}\n",
       "landmark {\n",
       "  x: 0.8325755000114441\n",
       "  y: 0.5524455308914185\n",
       "  z: -0.2932988703250885\n",
       "  visibility: 0.9971161484718323\n",
       "}\n",
       "landmark {\n",
       "  x: 0.8180640935897827\n",
       "  y: 0.7383368015289307\n",
       "  z: 0.43847328424453735\n",
       "  visibility: 0.9634199142456055\n",
       "}\n",
       "landmark {\n",
       "  x: 0.5487165451049805\n",
       "  y: 0.6469444036483765\n",
       "  z: -0.6361316442489624\n",
       "  visibility: 0.9958636164665222\n",
       "}\n",
       "landmark {\n",
       "  x: 0.9064954519271851\n",
       "  y: 0.9920122027397156\n",
       "  z: 0.40336543321609497\n",
       "  visibility: 0.08069182932376862\n",
       "}\n",
       "landmark {\n",
       "  x: 0.6486836671829224\n",
       "  y: 0.9757825136184692\n",
       "  z: -0.8014853596687317\n",
       "  visibility: 0.8037349581718445\n",
       "}\n",
       "landmark {\n",
       "  x: 0.9346297383308411\n",
       "  y: 1.0611616373062134\n",
       "  z: -0.08730774372816086\n",
       "  visibility: 0.1363430917263031\n",
       "}\n",
       "landmark {\n",
       "  x: 0.9975144267082214\n",
       "  y: 1.0577480792999268\n",
       "  z: -0.5989580154418945\n",
       "  visibility: 0.7101040482521057\n",
       "}\n",
       "landmark {\n",
       "  x: 0.894825279712677\n",
       "  y: 1.1160789728164673\n",
       "  z: -0.21650762856006622\n",
       "  visibility: 0.1740824282169342\n",
       "}\n",
       "landmark {\n",
       "  x: 1.1381559371948242\n",
       "  y: 1.0833135843276978\n",
       "  z: -0.6669913530349731\n",
       "  visibility: 0.6985315084457397\n",
       "}\n",
       "landmark {\n",
       "  x: 0.8682528734207153\n",
       "  y: 1.0417280197143555\n",
       "  z: -0.20013193786144257\n",
       "  visibility: 0.21022802591323853\n",
       "}\n",
       "landmark {\n",
       "  x: 1.1416566371917725\n",
       "  y: 1.0119047164916992\n",
       "  z: -0.6662461161613464\n",
       "  visibility: 0.7438176870346069\n",
       "}\n",
       "landmark {\n",
       "  x: 0.8913817405700684\n",
       "  y: 1.0259242057800293\n",
       "  z: -0.11184314638376236\n",
       "  visibility: 0.20764145255088806\n",
       "}\n",
       "landmark {\n",
       "  x: 1.1011178493499756\n",
       "  y: 0.9992477297782898\n",
       "  z: -0.5874543190002441\n",
       "  visibility: 0.7010765671730042\n",
       "}\n",
       "landmark {\n",
       "  x: 0.8063727617263794\n",
       "  y: 1.4802502393722534\n",
       "  z: 0.24550358951091766\n",
       "  visibility: 0.004588112235069275\n",
       "}\n",
       "landmark {\n",
       "  x: 0.5996717214584351\n",
       "  y: 1.4874402284622192\n",
       "  z: -0.24226650595664978\n",
       "  visibility: 0.005431922618299723\n",
       "}\n",
       "landmark {\n",
       "  x: 0.8667638897895813\n",
       "  y: 1.8659528493881226\n",
       "  z: 0.02585747465491295\n",
       "  visibility: 0.023845581337809563\n",
       "}\n",
       "landmark {\n",
       "  x: 0.6765468120574951\n",
       "  y: 1.8349878787994385\n",
       "  z: -0.30676859617233276\n",
       "  visibility: 0.029797399416565895\n",
       "}\n",
       "landmark {\n",
       "  x: 0.8845545649528503\n",
       "  y: 2.440974235534668\n",
       "  z: 0.36362501978874207\n",
       "  visibility: 0.002065794775262475\n",
       "}\n",
       "landmark {\n",
       "  x: 0.7022517919540405\n",
       "  y: 2.486201286315918\n",
       "  z: -0.05154161527752876\n",
       "  visibility: 0.0016316467663273215\n",
       "}\n",
       "landmark {\n",
       "  x: 0.8611690402030945\n",
       "  y: 2.527332305908203\n",
       "  z: 0.3767296373844147\n",
       "  visibility: 0.0021194980945438147\n",
       "}\n",
       "landmark {\n",
       "  x: 0.6532527208328247\n",
       "  y: 2.599613666534424\n",
       "  z: -0.042737722396850586\n",
       "  visibility: 0.001970944693312049\n",
       "}\n",
       "landmark {\n",
       "  x: 0.9564124941825867\n",
       "  y: 2.6009626388549805\n",
       "  z: 0.0624975860118866\n",
       "  visibility: 0.005739932414144278\n",
       "}\n",
       "landmark {\n",
       "  x: 0.8648245930671692\n",
       "  y: 2.629997730255127\n",
       "  z: -0.404396116733551\n",
       "  visibility: 0.004850247874855995\n",
       "}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## to see the coordinates of each and every land mark that the media pipe detect we need to do\n",
    "results.pose_landmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f8434465",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "frozenset({(0, 1),\n",
       "           (0, 4),\n",
       "           (1, 2),\n",
       "           (2, 3),\n",
       "           (3, 7),\n",
       "           (4, 5),\n",
       "           (5, 6),\n",
       "           (6, 8),\n",
       "           (9, 10),\n",
       "           (11, 12),\n",
       "           (11, 13),\n",
       "           (11, 23),\n",
       "           (12, 14),\n",
       "           (12, 24),\n",
       "           (13, 15),\n",
       "           (14, 16),\n",
       "           (15, 17),\n",
       "           (15, 19),\n",
       "           (15, 21),\n",
       "           (16, 18),\n",
       "           (16, 20),\n",
       "           (16, 22),\n",
       "           (17, 19),\n",
       "           (18, 20),\n",
       "           (23, 24),\n",
       "           (23, 25),\n",
       "           (24, 26),\n",
       "           (25, 27),\n",
       "           (26, 28),\n",
       "           (27, 29),\n",
       "           (27, 31),\n",
       "           (28, 30),\n",
       "           (28, 32),\n",
       "           (29, 31),\n",
       "           (30, 32)})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## to see the pose connectionsof each and every land mark that the media pipe detect we need to do\n",
    "## numbers 0,1,2,3 etc represent the detected joints on the body the full description is given in  media pipe documentation\n",
    "## https://google.github.io/mediapipe/solutions/pose\n",
    "mp_pose.POSE_CONNECTIONS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb558243",
   "metadata": {},
   "source": [
    "# Determining Joints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bcce86a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## There ar 33 landmarks IT STARTS FROM 0 as shown in image pose_tracking_full_body_landmarks.png \n",
    "cap=cv.VideoCapture(0) #using this we can use our video input decice to input the video\n",
    "## setting up mediia pipe instance\n",
    "with mp_pose.Pose(min_detection_confidence=0.5 , min_tracking_confidence = 0.5) as pose: # our detection confidance will be 50% and tracking confdence is 50% the line is accessible with variable pose \n",
    "    while cap.isOpened(): # this is going to loop through the live feed \n",
    "        ret , frame = cap.read()\n",
    "        \n",
    "        # RECOLOR IMAGE TO RGB\n",
    "        image= cv.cvtColor(frame,cv.COLOR_BGR2RGB) ## media pile wants the image in a specific format so we are re arranging the image here\n",
    "        image.flags.writeable = False\n",
    "        \n",
    "        # MAKE DETECTIONS\n",
    "        results= pose.process(image) ## using pose variable we are processing the image and making detections in the image and storing them in results variable \n",
    "        \n",
    "        # RECOLOURING BACK TO BGR\n",
    "        image.flags.writeable = True\n",
    "        image = cv.cvtColor(image,cv.COLOR_RGB2BGR) # now we are rearranging back in to the format which open cv accepts \n",
    "        \n",
    "        \n",
    "        # EXTRACTING THE LANDMARKS \n",
    "        try:\n",
    "            landmarks = results.pose_landmarks.landmark\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        #RENDERING DETECTIONS\n",
    "        mp_drawing.draw_landmarks(image,results.pose_landmarks,mp_pose.POSE_CONNECTIONS,\n",
    "                                  mp_drawing.DrawingSpec(color = (245,117,66), thickness = 2 , circle_radius = 2), ## this is the land mard drawing spec\n",
    "                                  mp_drawing.DrawingSpec(color = (245,66,280), thickness = 2 , circle_radius = 2)  ## this is the connection drawing spec \n",
    "                                 #DrawingSpec is the specification of a drawing component\n",
    "                                 )\n",
    "        \n",
    "        cv.imshow('Mediapipe Feed',image) #this  will give us a pope up on the screen and help us to visuva;ize the feed\n",
    "\n",
    "        if cv.waitKey(10) & 0xFF == ord('q'): # this is used to close our screen it checks weather the user is hitting q to close the wondow\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ff18d0b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "x: 0.7368040084838867\n",
       "y: 0.8001561760902405\n",
       "z: 0.0050335051491856575\n",
       "visibility: 0.9981982707977295"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## let us access some land marks \n",
    "\n",
    "landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "97077833",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# to get its respective index\n",
    "mp_pose.PoseLandmark.LEFT_SHOULDER.value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a75908d",
   "metadata": {},
   "source": [
    "# Calculate Angles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2470cf80",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Basically this function calculate angle between three points\n",
    "def calculate_angela(a,b,c): ## a,b,c represent left_sholder,left_elbow,left_wrist . \n",
    "    a = np.array(a) #first\n",
    "    b = np.array(b) #second\n",
    "    c = np.array(c) #third\n",
    "    \n",
    "    radians = np.arctan2(c[1]-b[1] , c[0]-b[0]) - np.arctan2(a[1]-b[1] , a[0]-b[0])\n",
    "    angle = np.abs(radians*180.0/np.pi)\n",
    "    \n",
    "    if angle >180.0:\n",
    "        angle = 360-angle\n",
    "        \n",
    "    return angle\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c9c517af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([0.7368040084838867, 0.8001561760902405],\n",
       " [0.9121123552322388, 0.9643701910972595],\n",
       " [1.0715174674987793, 1.0526318550109863])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking the angle caluculation function\n",
    "\n",
    "shoulder = [landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].x,landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].y]\n",
    "elbow = [landmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value].x,landmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value].y]\n",
    "wrist = [landmarks[mp_pose.PoseLandmark.LEFT_WRIST.value].x,landmarks[mp_pose.PoseLandmark.LEFT_WRIST.value].y]\n",
    "shoulder,elbow ,wrist "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e527a67e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "165.84458625587826"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_angela(shoulder,elbow ,wrist )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "78f95e4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# There ar 33 landmarks IT STARTS FROM 0 as shown in image pose_tracking_full_body_landmarks.png \n",
    "cap=cv.VideoCapture(0) #using this we can use our video input decice to input the video\n",
    "cap.set(cv.CAP_PROP_FRAME_WIDTH, 640)\n",
    "cap.set(cv.CAP_PROP_FRAME_HEIGHT, 480)\n",
    "width = cap.get(cv.CAP_PROP_FRAME_WIDTH)\n",
    "height = cap.get(cv.CAP_PROP_FRAME_HEIGHT)\n",
    "## setting up mediia pipe instance\n",
    "with mp_pose.Pose(min_detection_confidence=0.5 , min_tracking_confidence = 0.5) as pose: # our detection confidance will be 50% and tracking confdence is 50% the line is accessible with variable pose \n",
    "    while cap.isOpened(): # this is going to loop through the live feed \n",
    "        ret , frame = cap.read()\n",
    "        \n",
    "        # RECOLOR IMAGE TO RGB\n",
    "        image= cv.cvtColor(frame,cv.COLOR_BGR2RGB) ## media pile wants the image in a specific format so we are re arranging the image here\n",
    "        image.flags.writeable = False\n",
    "        \n",
    "        # MAKE DETECTIONS\n",
    "        results= pose.process(image) ## using pose variable we are processing the image and making detections in the image and storing them in results variable \n",
    "        \n",
    "        # RECOLOURING BACK TO BGR\n",
    "        image.flags.writeable = True\n",
    "        image = cv.cvtColor(image,cv.COLOR_RGB2BGR) # now we are rearranging back in to the format which open cv accepts \n",
    "        \n",
    "        \n",
    "        # EXTRACTING THE LANDMARKS \n",
    "        try:\n",
    "            landmarks = results.pose_landmarks.landmark\n",
    "            \n",
    "            # GET COORDINATES\n",
    "            shoulder = [landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER.value].x,landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].y]\n",
    "            elbow = [landmarks[mp_pose.PoseLandmark.RIGHT_ELBOW.value].x,landmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value].y]\n",
    "            wrist = [landmarks[mp_pose.PoseLandmark.RIGHT_WRIST.value].x,landmarks[mp_pose.PoseLandmark.LEFT_WRIST.value].y]\n",
    "            \n",
    "            #calculate the angle\n",
    "            \n",
    "            angle=calculate_angela(shoulder,elbow ,wrist)\n",
    "            \n",
    "            # VISUVALIZE ANGLE\n",
    "            cv.putText(image, str(angle),\n",
    "                       tuple(np.multiply(elbow,[640,480]).astype(int)),\n",
    "                       cv.FONT_HERSHEY_SIMPLEX,0.5,(225,225,225),2,cv.LINE_AA)\n",
    "                      \n",
    "                       \n",
    "                               \n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        #RENDERING DETECTIONS\n",
    "        mp_drawing.draw_landmarks(image,results.pose_landmarks,mp_pose.POSE_CONNECTIONS,\n",
    "                                  mp_drawing.DrawingSpec(color = (245,117,66), thickness = 2 , circle_radius = 2), ## this is the land mard drawing spec\n",
    "                                  mp_drawing.DrawingSpec(color = (245,66,280), thickness = 2 , circle_radius = 2)  ## this is the connection drawing spec \n",
    "                                 #DrawingSpec is the specification of a drawing component\n",
    "                                 )\n",
    "        \n",
    "        cv.imshow('Mediapipe Feed',image) #this  will give us a pope up on the screen and help us to visuva;ize the feed\n",
    "\n",
    "        if cv.waitKey(10) & 0xFF == ord('q'): # this is used to close our screen it checks weather the user is hitting q to close the wondow\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "658e7cde",
   "metadata": {},
   "source": [
    "# Curl Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "8f88e02d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    }
   ],
   "source": [
    "# There ar 33 landmarks IT STARTS FROM 0 as shown in image pose_tracking_full_body_landmarks.png \n",
    "cap=cv.VideoCapture(0) #using this we can use our video input decice to input the video\n",
    "cap.set(cv.CAP_PROP_FRAME_WIDTH, 640)\n",
    "cap.set(cv.CAP_PROP_FRAME_HEIGHT, 480)\n",
    "width = cap.get(cv.CAP_PROP_FRAME_WIDTH)\n",
    "height = cap.get(cv.CAP_PROP_FRAME_HEIGHT)\n",
    "\n",
    "# curl counter variables\n",
    "counter = 0 # counts number of reps \n",
    "stage = None # determines the position like bottem of rep or top of the rep\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## setting up mediia pipe instance\n",
    "with mp_pose.Pose(min_detection_confidence=0.5 , min_tracking_confidence = 0.5) as pose: # our detection confidance will be 50% and tracking confdence is 50% the line is accessible with variable pose \n",
    "    while cap.isOpened(): # this is going to loop through the live feed \n",
    "        ret , frame = cap.read()\n",
    "        \n",
    "        # RECOLOR IMAGE TO RGB\n",
    "        image= cv.cvtColor(frame,cv.COLOR_BGR2RGB) ## media pile wants the image in a specific format so we are re arranging the image here\n",
    "        image.flags.writeable = False\n",
    "        \n",
    "        # MAKE DETECTIONS\n",
    "        results= pose.process(image) ## using pose variable we are processing the image and making detections in the image and storing them in results variable \n",
    "        \n",
    "        # RECOLOURING BACK TO BGR\n",
    "        image.flags.writeable = True\n",
    "        image = cv.cvtColor(image,cv.COLOR_RGB2BGR) # now we are rearranging back in to the format which open cv accepts \n",
    "        \n",
    "        \n",
    "        # EXTRACTING THE LANDMARKS \n",
    "        try:\n",
    "            landmarks = results.pose_landmarks.landmark\n",
    "            \n",
    "            # GET COORDINATES\n",
    "            shoulder = [landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER.value].x,landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].y]\n",
    "            elbow = [landmarks[mp_pose.PoseLandmark.RIGHT_ELBOW.value].x,landmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value].y]\n",
    "            wrist = [landmarks[mp_pose.PoseLandmark.RIGHT_WRIST.value].x,landmarks[mp_pose.PoseLandmark.LEFT_WRIST.value].y]\n",
    "            \n",
    "            #calculate the angle\n",
    "            \n",
    "            angle=calculate_angela(shoulder,elbow ,wrist)\n",
    "            \n",
    "            # VISUVALIZE ANGLE\n",
    "            cv.putText(image, str(angle),\n",
    "                       tuple(np.multiply(elbow,[640,480]).astype(int)),\n",
    "                       cv.FONT_HERSHEY_SIMPLEX,0.5,(225,225,225),2,cv.LINE_AA)\n",
    "            \n",
    "            # Curl counter logic\n",
    "            if angle > 160:\n",
    "                stage = \"down\"\n",
    "            if angle < 30 and stage == \"down\":\n",
    "                stage = \"up\"\n",
    "                counter+=1\n",
    "                print (counter)\n",
    "                \n",
    "            ## THRESHOLDS ##\n",
    "            ## THE 160 DEGREE DOWN THRESHOLD GIVES YOU LEEWAY IN CASE YOU DONT GET A PERFECT180 DEGREE STRAIGHT ##\n",
    "            ## THE 30 DEGREE UP THRESHOLD ESURES A REP THAT DOSENT GO ALL THE WAY UP IS COUNTED ##\n",
    "            \n",
    "                      \n",
    "                       \n",
    "                               \n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        ## Render curl counter\n",
    "        #3 setup status ba=ox\n",
    "        cv.rectangle(image,(0,0),(225,73),(245,117,16),-1)\n",
    "        \n",
    "        #rep data\n",
    "        cv.putText(image,'Reps',(15,12),\n",
    "                    cv.FONT_HERSHEY_SIMPLEX,0.5,(0,0,0),1,cv.LINE_AA)\n",
    "        cv.putText(image,str(counter),\n",
    "                    (10,60),\n",
    "                    cv.FONT_HERSHEY_SIMPLEX,2,(225,225,225),2,cv.LINE_AA)\n",
    "        \n",
    "        #RENDERING DETECTIONS\n",
    "        mp_drawing.draw_landmarks(image,results.pose_landmarks,mp_pose.POSE_CONNECTIONS,\n",
    "                                  mp_drawing.DrawingSpec(color = (245,117,66), thickness = 2 , circle_radius = 2), ## this is the land mard drawing spec\n",
    "                                  mp_drawing.DrawingSpec(color = (245,66,280), thickness = 2 , circle_radius = 2)  ## this is the connection drawing spec \n",
    "                                 #DrawingSpec is the specification of a drawing component\n",
    "                                 )\n",
    "        \n",
    "        cv.imshow('Mediapipe Feed',image) #this  will give us a pope up on the screen and help us to visuva;ize the feed\n",
    "\n",
    "        if cv.waitKey(10) & 0xFF == ord('q'): # this is used to close our screen it checks weather the user is hitting q to close the wondow\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fc60b24",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
